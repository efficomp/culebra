# This file is part of culebra.
#
# Culebra is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# Culebra is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# Culebra. If not, see <http://www.gnu.org/licenses/>.
#
# This work was supported by project PGC2018-098813-B-C31 (Spanish "Ministerio
# de Ciencia, Innovación y Universidades"), and by the European Regional
# Development Fund (ERDF).

"""Provides the :py:class:`~tools.experiment.Experiment` class."""

import os
import numpy as np
import pandas as pd
from culebra.tools.feature_metrics import relevance, rank

__author__ = 'Jesús González'
__copyright__ = 'Copyright 2021, EFFICOMP'
__license__ = 'GNU GPL-3.0-or-later'
__version__ = '0.1.1'
__maintainer__ = 'Jesús González'
__email__ = 'jesusgonzalez@ugr.es'
__status__ = 'Development'


class Labels:
    """Labels for the results dataframes."""

    individual = 'Individual'
    """Label for the individual column in the dataframes"""

    feature = 'Feature'
    """Label for the feature column in the dataframes"""

    phase = 'Phase'
    """Label for the phase column in the dataframes"""

    training = 'Training'
    """Training phase label"""

    test = 'Test'
    """Test phase label"""

    fitness = 'Fitness'
    """Label for the fitness column in the dataframes"""

    relevance = 'Relevance'
    """Label for the relevance column in the dataframes"""

    rank = 'Rank'
    """Label for the rank column in the dataframes"""

    max = 'Max'
    """Label for the max column in the dataframes"""

    min = 'Min'
    """Label for the min column in the dataframes"""

    avg = 'Avg'
    """Label for the avg column in the dataframes"""

    std = 'Std'
    """Label for the std column in the dataframes"""

    best = 'Best'
    """Label for the best column in the dataframes"""

    stat = 'Stat'
    """Label for the stat column in the dataframes"""

    metric = 'Metric'
    """Label for the metric column in the dataframes"""

    runtime = "Runtime"
    """Label for the runtime column in dataframes."""


class Files:
    """Files generated by the experiment."""

    script = "run.py"
    """Name for the script to run an experiment."""

    backup = "backup.gz"
    """Default name for the file to backup the experiment."""

    results = "results.xlsx"
    """Name for the file to store the results."""


DEFAULT_TEST_STATS = {Labels.avg: np.mean,
                      Labels.std: np.std,
                      Labels.min: np.min,
                      Labels.max: np.max}
"""Default statistics calculated for tested solutions."""

DEFAULT_FEATURE_METRICS = {Labels.relevance: relevance,
                           Labels.rank: rank}
"""Default metrics calculated for the features in the set of solutions."""


class Experiment:
    """Run a wrapper method from the parameters in a config file."""

    results_names = ("training_stats", "solutions", "test_stats",
                     "best_solutions", "feature_metrics", "execution_metrics")
    """Names of the different results provided by this experiment."""

    feature_metrics = DEFAULT_FEATURE_METRICS
    """Metrics calculated for the features in the set of solutions."""

    test_stats = DEFAULT_TEST_STATS
    """Statistics calculated for the tested solutions."""

    def __init__(self, wrapper, tr_data, tr_fitness, tst_data=None,
                 tst_fitness=None):
        """Set an experiment to run a wrapper method.

        :param wrapper: The wrapper method
        :type wrapper: Any subclass of :py:class:`~base.wrapper.Wrapper`.
        :param tr_data: Training data
        :type tr_data: :py:class:`~base.dataset.Dataset`
        :param tr_fitness: The fitness used for training
        :type tr_fitness: Any subclass of :py:class:`~base.fitness.Fitness`
        :param tst_data: Test data. If `None`, *tr_data* will be used. Defaults
            to `None`
        :type tst_data: :py:class:`~base.dataset.Dataset`, optional
        :param tst_fitness: The fitness used to test. If `None`, *tr_fitness*
            will be used. Defaults to `None`.
        :type tst_fitness: Any subclass of :py:class:`~base.fitness.Fitness`,
            optional
        """
        self._wrapper = wrapper

        self._tr_data = tr_data
        self._tst_data = tst_data if tst_data else tr_data

        self._tr_fitness = tr_fitness
        self._tst_fitness = tst_fitness if tst_fitness else tr_fitness

        # Reset results
        self.__reset()

    def run(self):
        """Run the wrapper method."""
        # Forget previous results
        self.__reset()

        hof, runtime = self.__train()

        # Insert the runtime ina dataframe
        self.__add_execution_metrix(Labels.runtime, runtime)

        # Get the features stats
        self.__do_feature_metrics(hof)

        # Test the best solutions found
        hof = self.__test(hof)

        # Get the best solutions found
        self.__do_best_solutions(hof)

    def save(self, file=None):
        """Save this experiment.

        :param file: File to store the experiment. Defaults to
            :py:attr:`~tools.experiment.Files.backup_file`
        :type file: A path to a file, optional.
        """
        file = Files.backup if file is None else file
        pd.io.pickle.to_pickle(self, file)

    @classmethod
    def load(cls, file=None):
        """Load an experiment.

        :param file: File to load the experiment from. Defaults to
            :py:attr:`~tools.experiment.Files.backup_file`
        :type file: A path to a file, optional.
        """
        file = Files.backup if file is None else file
        return pd.io.pickle.read_pickle(file)

    @classmethod
    def generate_script(cls, config, file=None):
        """Generate a script to run the experiment.

        :param config: Path to the configuration file
        :type config: :py:class:`str`
        :param file: File to store the script. Defaults to
            :py:attr:`~tools.experiment.Files.script_file`
        :type file: A path to a file, optional.
        """
        SCRIPT = """#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from culebra.tools.config_manager import ConfigManager

# Parameter file
CONFIG = "{config_file}"

# Get the configuration parameters
config_manager = ConfigManager(CONFIG)

# Create the experiment
experiment = config_manager.build_experiment()

# Run the experiment
experiment.run()

# Save the experiment
experiment.save()

# Save the results to Excel
experiment.results_to_excel()

# Print the results
for res, val in experiment.results.items():
    print(f"\\n\\n{res}:")
    print(val)
"""
        """Parameterized script to run as experiment."""

        file = Files.script if file is None else file

        # Create the script
        with open(file, 'w') as script:
            script.write(SCRIPT.format_map({"config_file": config,
                                            "res": "{res}"}))

        # Make the script executable
        os.chmod(file, 0o777)

    @property
    def results(self):
        """Results of this experiment.

        :type: :py:class:`dict`
        """
        return {key: getattr(self, self.__data_name(key))
                for key in self.results_names}

    def results_to_excel(self, file=None):
        """Save the results to a Excel file.

        :param file: File to store the results. Defaults to
            :py:attr:`~tools.experiment.Files.results_file`
        :type file: A path to a file, optional.
        """
        file = Files.results if file is None else file

        with pd.ExcelWriter(file) as writer:
            for name, data in self.results.items():
                data.to_excel(writer, sheet_name=name)

            writer.save()

    def __data_name(self, name):
        """Return the name of an experiment."""
        data_suffix = "data"

        return "_" + name + "_" + data_suffix

    def __reset(self):
        """Reset the experient results."""
        # Reset all the results data structures
        for key in self.results_names:
            setattr(self, self.__data_name(key), None)

    def __add_execution_metrix(self, name, value):
        """Add an execution metric.

        :param name: Name of the metric
        :type name: :py:class:`str`
        :param value: Value of the metric
        :type value: :py:class:`object`
        """
        # Create the DataFrame if it doesn't exist
        if self._execution_metrics_data is None:
            self._execution_metrics_data = pd.DataFrame()
            self._execution_metrics_data.columns.set_names(
                [Labels.metric], inplace=True)

        self._execution_metrics_data[name] = [value]

    def __do_best_solutions(self, hof):
        """Generate a DataFrame with the best solutions found.

        :param hof: The best individuals found
        :type hof: :py:class:`~deap.tools.HallOfFame` of individuals
        """
        # Find the best wvalue for each objectuve
        best_wvalues = None
        for ind in hof:
            # Init
            if best_wvalues is None:
                fitness_names = ind.fitness.names
                best_wvalues = list(ind.fitness.wvalues)
                n_obj = ind.fitness.n_obj
                sim_th = ind.fitness.thresholds

            # Update the best wvalues
            for obj in range(n_obj):
                if ind.fitness.wvalues[obj] > best_wvalues[obj]:
                    best_wvalues[obj] = ind.fitness.wvalues[obj]

        # Columns for the dataframe
        best_fitness_names = []
        best_values = []
        best_inds = []

        # Find the individuals having wvalues similar to the best ones
        for ind in hof:
            for obj, th in zip(range(n_obj), sim_th):
                if best_wvalues[obj] - ind.fitness.wvalues[obj] <= th:
                    best_fitness_names += [fitness_names[obj]]
                    best_values += [ind.fitness.values[obj]]
                    best_inds += [ind]

        # Create the dataframe
        self._best_solutions_data = pd.DataFrame()

        # Insert the data
        self._best_solutions_data[Labels.fitness] = best_fitness_names
        self._best_solutions_data[Labels.test] = best_values
        self._best_solutions_data[Labels.individual] = best_inds

        self._best_solutions_data.set_index([Labels.fitness],
                                            inplace=True)
        self._best_solutions_data.sort_index(inplace=True)
        self._best_solutions_data.columns.set_names([
                Labels.best], inplace=True)

    def __do_training_solutions(self, hof, *fitness_names):
        """Add the training fitness values to the solutions found.

        :param hof: Individuals to be appended
        :type hof: :py:class:`~deap.tools.HallOfFame` of individuals
        :param fitness_names: Fitness names
        :type fitness_names: :py:class:`list`
        """
        # Create the solutions dataframe
        self._solutions_data = pd.DataFrame(
                columns=[Labels.individual, Labels.fitness,
                         Labels.training])

        # For each solution found
        for ind in hof:
            # For each fitness objective
            for name, val in zip(fitness_names, ind.fitness.values):
                data = {Labels.individual: ind,
                        Labels.fitness: name,
                        Labels.training: val}
                self._solutions_data = (
                    self._solutions_data.append(data, ignore_index=True))

    def __do_test_solutions(self, hof):
        """Add the test fitness values to the solutions found.

        :param hof: Individuals to be appended
        :type hof: :py:class:`~deap.tools.HallOfFame` of individuals
        """
        values = []
        # For each solution found
        for ind in hof:
            # For each fitness objective
            for val in ind.fitness.values:
                values += [val]

        # Add the test fitness values
        self._solutions_data[Labels.test] = values

        self._solutions_data.set_index(
            [Labels.individual, Labels.fitness], inplace=True)
        self._solutions_data.sort_index(inplace=True)

        self._solutions_data.columns.set_names(
            [Labels.phase], inplace=True)

    def __do_feature_metrics(self, hof):
        """Perform stats about features frequency in the set of solutions.

        :param hof: The best individuals found
        :type hof: :py:class:`~deap.tools.HallOfFame` of individuals
        """
        # Create the dataframe
        self._feature_metrics_data = pd.DataFrame()

        # Perform the stats
        for name, func in self.feature_metrics.items():
            self._feature_metrics_data[name] = func(hof)

        self._feature_metrics_data.index.names = [Labels.feature]
        self._feature_metrics_data.columns.set_names(
            [Labels.metric], inplace=True)

    def __do_training_stats(self, logbook):
        """Perform the training stats from a logbook.

        :param logbook: The logbook
        :type logbook: :py:class:`~deap.tools.Logbook`
        """
        # Number of generations in the logbook
        n_gens = len(logbook)

        # Number of objectives
        n_obj = self._tr_fitness.n_obj

        # Create the dataframe
        self._training_stats_data = pd.DataFrame()

        # Add the generational stats
        index = []
        for stat in self._wrapper.stats_names:
            self._training_stats_data[stat.capitalize()] = \
                logbook.select(stat)*n_obj
            index += [stat.capitalize()]

        # Index for each objective stats
        fitness_index = []
        for i in range(n_obj):
            fitness_index += [self._tr_fitness.names[i]]*n_gens
        self._training_stats_data[Labels.fitness] = fitness_index

        # For each objective stat
        for stat in self._wrapper.objective_stats_names:
            # Select the data of this stat for all the objectives
            data = logbook.select(stat)
            stat_data = np.zeros(n_gens*n_obj)
            for i in range(n_gens):
                for j in range(len(data[i])):
                    stat_data[j*n_gens + i] = data[i][j]

            self._training_stats_data[stat.capitalize()] = stat_data

        self._training_stats_data.set_index(index + [Labels.fitness],
                                            inplace=True)
        self._training_stats_data.sort_index(inplace=True)
        self._training_stats_data.columns.set_names(
            [Labels.stat], inplace=True)

    def __do_test_stats(self, hof):
        """Perform some stats on the tested solutions.

        :param hof: The best individuals found (evaluated with test data)
        :type hof: :py:class:`~deap.tools.HallOfFame` of individuals
        """
        # Number of objectives
        n_obj = self._tst_fitness.n_obj

        # Number of individuals in the hof
        n_ind = len(hof)

        # Array to store all the fitnesses
        fitness = np.zeros([n_obj, n_ind])

        # Check all the solutions
        for i, ind in zip(range(n_ind), hof):
            fitness[:, i] = ind.fitness.values

        # Create the dataframe
        self._test_stats_data = pd.DataFrame()

        # Perform the stats
        self._test_stats_data[Labels.fitness] = self._tst_fitness.names
        for name, func in self.test_stats.items():
            self._test_stats_data[name] = func(fitness, axis=1)

        self._test_stats_data.set_index([Labels.fitness], inplace=True)
        self._test_stats_data.sort_index(inplace=True)
        self._test_stats_data.columns.set_names([
                Labels.stat], inplace=True)

    def __train(self):
        """Perform the training step.

        Train the wrapper and append the solutions to the best solutions
        dataframe.

        :return: The best individuals found
        :rtype: :py:class:`~deap.tools.HallOfFame` of individuals
        :return: The runtime of the algorithm
        :rtype: :py:class:`float`
        """
        # Search the best solutions
        hof, logbook, runtime = self._wrapper.train(self._tr_data,
                                                    self._tr_fitness)

        # Add the training fitness to the best solutions dataframe
        self.__do_training_solutions(hof, *self._tr_fitness.names)

        # Get the training stats from the logbook
        self.__do_training_stats(logbook)

        # Return the best solutions found
        return hof, runtime

    def __test(self, hof):
        """Perform the test step.

        Test the solutions found by the wrapper append their fitness to the
        best solutions dataframe.

        :param hof: The best individuals found
        :type hof: :py:class:`~deap.tools.HallOfFame` of individuals
        :return: The best solutions found, updated with the test fitness
        :rtype: :py:class:`~deap.tools.HallOfFame` of individuals
        """
        # Test the best solutions found
        self._wrapper.test(hof, self._tst_data, self._tst_fitness)

        # Add the test fitness to the best solutions dataframe
        self.__do_test_solutions(hof)

        # Perform the test stats
        self.__do_test_stats(hof)

        # Update the hof
        hof.update(hof)

        return hof
